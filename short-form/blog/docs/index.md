# How LLMs and Children Learn Languages

The other day, I was working on a very basic Large Language Model (LLM)
implementation from scratch. In the early phases of training the LLM would
respond to prompts with random noise - as is expected for an untrained model.

I knew the theory, but seeing it in practice made me think about my three year
old cousin. When she was learning to speak, she started by making (apparently)
random sounding noises which over time became words and sentences. Now, she's
able to hold conversations. I wanted to find out what the similarities and
differences were between how children learn language and how LLMs "learn"
language.

This blog post will focus mainly on a branch of linguistics called _Child
Language Development_ (CLD). I will draw comparisons to LLMs but won't go into
detail on how they are trained. If you are interested, [Spheron](https://blog.spheron.network/how-to-build-an-llm-from-scratch-a-step-by-step-guide) has a good blog post about LLMs from scratch.

<figure style="text-align: center">
  <img src="https://imgs.xkcd.com/comics/language_acquisition.png" width="200">
  <figcaption>XKCD Comic: Language Acquistion</figcaption>
</figure>
